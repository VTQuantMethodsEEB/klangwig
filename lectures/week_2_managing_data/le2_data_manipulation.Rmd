---
title: "Managing Data in R"
author: "KEL - Quantitative Methods"
output:
  ioslides_presentation: default
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
```
## Housekeeping

- You need some data for this class (assignment one)
- If you still do not have data, and do not have a plan to acquire data (e.g. chatting with your advisor, surfing dryad, using some from a cool paper you recently read), we need to speak about your options ASAP.
- Please email me klangwig@vt.edu if you are worried about this.

- **I need your github username turned in before next class**

## Assignment Reminder

- Please turn in your GitHub name and the paragraph about your data on canvas. 
    + There is a text entry box to do this under the "assignments" tab. (You don't need to send me an email or a canvas message.)


      
## Goals

You should be able to

-  read data into R
- understand and control how R represents those data
    - numbers, characters, factors, missing values
- examine the data visually, numerically, textually, etc.

##  Getting Started with Data
- Save files as .csv

- IMPORTANT – saving an excel file as a CSV means that you will lose some data
+ For example, if you used excel to calculate a formula, the formula will be gone as R will just store this as plain text
- DON’T USE EXCEL TO DO CALCULATIONS – JUST ADD THIS TO YOUR CODE IN R
- Use smart column names. R can’t handle spaces in your column names, so get rid of those. Also don’t use a bunch of capitals unnecessarily because it slows down your coding. e.g. use “species” not “Species”


## Making your excel file
- Excel files should have a list of column names at the top only and variable values

- Your excel file should not look like your field data sheet

## What is wrong with this entry?
```{r, out.width = "800px",echo=F}
knitr::include_graphics("bad_excel_pic.png")
```

## Corrected entry
```{r, out.width = "800px",echo=F}
knitr::include_graphics("corrected_datasheet.png")
```


## Representations

Numeric and character types are fairly straightforward, and you rarely
have to worry about when and whether R represents things as integers or *floating point*.

You do need to know about **factors**, and to be aware when your
variables are being treated as such. See lecture 1 for more about factors.

## Date reminder

Working with dates can be a bit frustrating because as time units get larger, they become more variable. For example, at what day does the 75th percentile of the month fall?

An important note – macs and windows machines often handle dates differently and the default is different in excel. 

One a mac the default is mo/day/two digit year – e.g. 01/13/18 is January 13, 2018, but on a PC the default is “01/13/2018”. This can result in some frustration between people sharing scripts!



## Missing values

When you input data, you need to be aware of `NA` ("not available"). Your
read function has an option called `na.strings` which you can use to
communicate between R and your CSV files, for example. You need to know
that

- use `is.na()` to test for `NA` values, `na.omit()` to drop them, and the optional `na.rm` argument in some functions (`mean`, `sum`, `median` ...)
- in the tidyverse, you can use `drop_na()` to remove `NA`

## Changing representations

- R has a big suite of functions for creating, testing and changing
representations. 

-These have names like `factor()`, `as.numeric()` and
`is.character()`.

## Examination

You should think creatively, and early on, about how to check your data.
Is it internally consistent? Are there extreme outliers? Are there
typos? Are there certain values that really mean something else?

An American Airlines memo about fuel reporting from the 1980s complained of multiple cases of:

-   Reported departure fuel greater than aircraft capacity
-   Reported departure fuel less than minimum required for trip
-   Reported arrival fuel greater than reported departure fuel


You should think about what you can test, and what you can fix if it's
broken.

## Things to fix in excel
- naming inconsistencies (see maple example last lecture)
- column name issues (spaces)
- use excel's find and replace and filter function to find these


## Visualizing data with graphs
Graphical approaches are really useful for data cleaning; we will
discuss this more later on.

To get you started here are just a few:

- `hist`: will make a histogram plot

## Example
```{r batdat, echo=TRUE}
batdat=read.csv("/Users/klangwig/Desktop/VT/teaching/quant grad course/github/klangwig/bat_data.csv")

head(batdat)  

```

## Example Cont. 
```{r unique, echo=TRUE}
unique(batdat$species)
```

## Example Cont. 
```{r hist, echo=TRUE}
hist(batdat$gd)
```

## Some other useful tools
- `dim`: gives the dimensions of the dataframe
- `str`: gives the structure of each variable
- `glimpse`: a dyplr function, that allows for preview as much of each column as possible
- `head`: get the first 6 rows
- `tail`: get the last 6 rows

## Some other useful base R tools
- `aggregate`: creating summary dfs using various functions on a set of variables
- `match`: match a value from one dataframe into another df given a common column. Only the value you want to copy is matched.
- `merge`: merge two dataframes together based on some common columns, all columns are merged.
- Note `merge` is made more versatile by the `join` functions in tidyverse

## Example with bat data
```{r counts1, echo=T}

batdat=read.csv("/Users/klangwig/Desktop/VT/teaching/quant grad course/github/klangwig/bat_data.csv")
head(batdat)

```

## Here, we will use aggregate
```{r aggregate, echo=T}
batcounts<-aggregate(count~species+site+date,data=batdat, FUN=mean) 
#make a df of bat counts
head(batcounts)
```

## We can make identical dataframes for loads
```{r loads, echo=T}
batdat$lgdL=log10(batdat$gdL)#log the amount of fungus
batloads<-aggregate(lgdL~species+site+date,data=batdat, FUN=mean)
head(batloads)
```

## We can "match" the loads column into our count df
```{r match, echo=T}
batloads$unique.row.id = paste(batloads$species,batloads$site,batloads$date)
batcounts$unique.row.id = paste(batcounts$species,batcounts$site,batcounts$date)
#dataframe you are bringing to first, and the one you matching from second
batloads$count = batcounts$count[match(batloads$unique.row.id,batcounts$unique.row.id)]
head(batloads)
```


## Alternatively, we can merge dataframes together for wide format
```{r merging, echo=T}
batwide=merge(batloads,batcounts,by=c("site","date"))
#merge df together by site and date
head(batwide)
```


## How do you clean data? 
What R functions do you know that are useful for examination? What are
your strategies?

## Tidy(ing) data

Hadley Wickham has defined a concept of [tidy
data](http://www.jstatsoft.org/v59/i10/paper), and has
introduced the `tidyverse` package.

-   Each variable is in a column
-   Each observation is in a row
-   "Long" rather than "wide" form
-   Sometimes duplicates data
-   Statistical modeling tools and graphical tools (especially the
    **ggplot2** package) in R work best with long form
    
## An example of tidy data
```{r, out.width = "800px",echo=F}
knitr::include_graphics("tidy_pic.png")
```

## Learning about the tidyverse
- https://www.tidyverse.org

## Putting your data in tidy format
- Discerning what is a variable can be hard when making data files
- For example, species in my bat dataset is usually a single variable
- I usually also include a "count" column (the number of individuals at a site)
- But what if I wanted to test the effect of the count of one species (e.g.MYSE)
  on another? 


## Example with bat count data
```{r remove_unique.id, echo=T}
batcounts<-aggregate(count~species+site+date,data=batdat, FUN=mean) 
head(batcounts)
```


## Testing the effect of one species on another
 - What if I wanted to test how the count of MYSE influenced counts of MYLU? I need to MYSE to be a variable

## Pivoting 
- Here is a link to vignette: https://tidyr.tidyverse.org/articles/pivot.html

- Using `pivot_wider()` and `pivot_longer()` we can specify how the metadata stored become data variables

- This has replaced `spread` and `gather`


## Let's 'pivot' (make wider)
```{r pivoting,echo=TRUE}
library(tidyr)
batcounts.wide<- batcounts %>% #this says - make a new df called batcounts.wide using bat counts
  pivot_wider(names_from = species, values_from = count) 
##make columns for each of the values in the species column and fill those columns with what is the count column
```



## What does our new df look like?
```{r examine,echo=TRUE}
head(batcounts.wide)
```


## Here's another example using "pivot"
 Look at some example data that comes with the tidyr package:

```{r view}
fish_encounters
```


## Pivot_wider

Using `pivot_wider()` 

```{r pivotwide}
fish_encounters %>%
  pivot_wider(names_from = station, values_from = seen)
```

## Fill in 0's

```{r pivotwide0s}
fish_encounters %>%
  pivot_wider(
    names_from = station,
    values_from = seen,
    values_fill = list(seen = 0)
  )
```

## Making a dataframe long (e.g. tidy)
Let's look at an example of an untidy dataframe.
```{r untidy}
head(relig_income)
```


## Make a row for the number of individuals for each religion by income category

```{r income_per_category}
relig_income %>%
  pivot_longer(-religion, names_to = "income", values_to = "count")
#the minus sign says don't include the column religion
#now you have a variable income and a count of the number of people that were in that income class
```

## Another example using temporal data:
The billboard dataset has a row for every week and the rank of that song
```{r billboard}
billboard
```


## We want week to be temporal data, but it has letters in it
- We want names to be a variable called "week" and the values to be a variable called "rank"
- We want to remove NAs because not all songs stay on the charts for 76 weeks

## Billboard
```{r billboard_longer}
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    names_prefix = "wk",
    values_to = "rank",
    values_drop_na = TRUE
  )
```

## Changing something to an integer
- We want to turn week into an integer so we can easily determine how long a song was on the charts
```{r replace_weeks}
billboard %>% 
  pivot_longer (
    cols = starts_with("wk"), 
    names_to = "week", 
    names_prefix = "wk",
    values_to = "rank",
    values_drop_na = TRUE
)
```


## So how do we create tidy datasets?
 - Make your data as tidy as possible
 - Learn to manipulate data in R and hardcode these changes into your scripts
 - There is no perfect method - each dataset is unique
 - Manipulating data in R is hard, sometimes harder than excel. But learning to do it SO worth it because you will save hours of time for each project you do. 

## Tools

#### base R

-   `reshape`: wide-to-long and vice versa
-   `merge`: join data frames
-   `ave`: compute averages by group
-   `subset`, `[`-indexing: select obs and vars
-   `transform`: modify variables and create new ones
-   `aggregate`: split-apply-summarize
-   `sort`

## The tidyverse

- `pivot_longer`, `pivot_wider`
- `mutate`: add a column
- `select`: select columns
- `filter`: select rows
- `group_by`: group then do something (usually mutate or summarise)
- `summarise`: make a summary table
- `arrange`: sort
- `left_join`: merge [see other `join` options](https://dplyr.tidyverse.org/reference/mutate-joins.html)
    
## Group by, Mutate, and Summarise
 - `group_by` is my favorite tidyverse command which has cut my need to write loops in half
 - `group_by` allows you to do calculations on groups of things, for example, by species or year
 
## First load the package
```{r load_tidyverse}
library(tidyverse)
```

## Group by species
```{r group_by_example}
batdat$lgdL = log10(batdat$gdL)
batdat %>% 
  group_by(species) %>% 
    summarise(mean.fungal.loads=mean(lgdL,na.rm=TRUE))
```

## Summarise versus Mutate
 - `summarise` creates a new dataframe 
 - `mutate` does a calculation where it add a new column to your existing dataframe
 
```{r mutate example}
batdat_with_sample_size = batdat %>% 
  #create a new dataframe  called batdat_with_sample_size
    group_by(site,species,date) %>% 
  #you can group_by multiple things
    mutate(sample.size=n())
#this adds a column to the dataframe
```

## What does our dataframe look like now?
```{r looking at new dataframe}
head(batdat_with_sample_size[c(1,6,7,8,12,13)])
#this is just showing a few columns for effect
```

 
## Managing Pipelines in R
- Pipelines are ways of carefully recording and systematizing the steps you take to work with your data

- The idea is that you should be able to delete any results of computer calculations and be able to quickly re-do them

- Ideally your project will depend on:
  -  Some data files
  -  Some scripts
  -  Something that tells you how these things go together (RMarkdown is helpful for this), at minimum a README file

## Advantages of this approach
 - Clarity: we aren't confused about the 600 pages of information stored with our projects
 
 - Reproducibility: we can always re-do something we did
 
 - Flexibility : we can use different data and re-create the same thing
 
## Spreadsheets
- Spreadsheets are a useful tool for working with R
- `read.csv` and `write.csv` are very useful commands for working with spreadsheets
- when using `write.csv` use `row.names=F` to avoid line numbers
- Importantly, spreadsheets are for storing data, NOT FOR MANIPULATING DATA
  -   Your goal should be to take data from a spreadsheet and manipulate it entirely using scripts. 
  -   Avoid spreadsheet addiction: http://www.burns-stat.com/documents/tutorials/spreadsheet-addiction/ 
  -   The jist is: friends don't let friends use excel for statistics. 

## Database
- Your spreadsheet is a database (just because it isn't stored in microsoft access doesn't mean it isn't!)
- "small" databases are usually considered to be fewer than 1000 observations of 10-20 vars
- "medium" databases are about 1000 to 100,000 observations of about 10-50 vars. These are most helpful with data handling packages. 
- "large" means millions of observations and potentially 1000s of variables. These may need to be stored in an external application. 

## Working in Github
- Git is version control system, with the original purpose of allowing groups to work collaboratively on software projects
- Git manages the evolution of a set of files - called a repository
- A repository is essentially a folder where you store your stuff
- Version control works a bit like "Track Changes" in word, Git will track the changes we make to our code so we can return to previous versions
- It also allows collaboration so I can look at your code and make changes - a bit like a more complicated version of Google Docs

## Will this hurt?
- Maybe! 

- But, I think this important enough that we NEED exposure to this. This is the future! 

## But I only code alone! 
- You need to carefully document your steps if the only person you are sharing code with is the future version of yourself

- In addition, most journals require publicly available data and code  - open code is the norm, not the exception.

- Using Git has gotten easier. We used to have to use command line to communicate with Git, but now we can just use RStudio! 

## Terminology

- repository: A directory or storage space where your projects can live. Sometimes GitHub users shorten this to “repo.” (If you're cool like that.) It is usually a local folder on your computer. You can keep code files, text files, image files, you name it, inside a repository.

- commit: This is the command that gives Git its power. When you commit, you are taking a “snapshot” of your repository at that point in time, giving you a checkpoint to which you can reevaluate or restore your project to any previous state.When you first start "commiting", it is important to remember this is taking the picture, not SENDING the picture. (Sending is called "pushing")

## Terminology cont.

- branch: How do multiple people work on a project at the same time without Git getting them confused? Usually, they “branch off” of the main project with their own versions full of changes they themselves have made. After they’re done, it’s time to “merge” that branch back with the “master,” the main directory of the project. Because we'll be working within our own repos, we don't need to worry too much about branching but is good to know for future.

- push: This is how you upload your file to GitHub. Remember, you need to both commit and push for your file to be sent to GitHub. 

## Sending your files to our class repository

- We have an "organization" account for our class
- Normally, we would have to pay for private repositories, but I emailed github and they are giving us UNLIMITED private repositories. That's pretty awesome.
- Why should we want things open-source? Why not? 

## Installing Git
 - Please try to start this before our next class. 
 - Here is a link: http://happygitwithr.com/install-git.html#install-git
 - Please follow instructions to get started with git. 
 - Try to install git in the most scientific way possible - if one way doesn't work, try the next, and google your mistakes! 
 



